{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80823f44-c2b0-4d32-b65a-071b8600e8b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/skasmani/Downloads/personal/github/CrewAI-Worksatation/crewai-venv/lib/python3.12/site-packages/pydantic/_internal/_config.py:295: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)\n",
      "/Users/skasmani/Downloads/personal/github/CrewAI-Worksatation/crewai-venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"schema\" in \"DatabricksQueryToolSchema\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n",
      "/Users/skasmani/Downloads/personal/github/CrewAI-Worksatation/crewai-venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:502: UserWarning: <built-in function callable> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "/Users/skasmani/Downloads/personal/github/CrewAI-Worksatation/crewai-venv/lib/python3.12/site-packages/crewai_tools/tools/scrapegraph_scrape_tool/scrapegraph_scrape_tool.py:34: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  @validator(\"website_url\")\n",
      "/Users/skasmani/Downloads/personal/github/CrewAI-Worksatation/crewai-venv/lib/python3.12/site-packages/crewai_tools/tools/selenium_scraping_tool/selenium_scraping_tool.py:26: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  @validator(\"website_url\")\n",
      "/Users/skasmani/Downloads/personal/github/CrewAI-Worksatation/crewai-venv/lib/python3.12/site-packages/crewai_tools/tools/vision_tool/vision_tool.py:15: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  @validator(\"image_path_url\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Worker LLM (ollama/hf.co/unsloth/Mistral-Small-3.1-24B-Instruct-2503-GGUF:Q5_K_M) initialized.\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mLinkedIn Post Scraper\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mScrape a LinkedIn profile to get some relevant posts\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mLinkedIn Post Scraper\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mScrapeLinkedinPosts\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "['Climbing the AI Agents Staircase ‚Äì One Step Closer to the Future!Every day, I get more fired up about what‚Äôs possible with Agentic AI! From simple LLMs to fully autonomous systems capable of planning, decision-making, and even self-learning‚Äîthis is the frontier of innovation, and we‚Äôre right in the thick of it.This awesome visual below breaks it all down‚Äîfrom the basics to the advanced, showing how we move from connecting APIs and memory management‚Ä¶ all the way up to agents that can think, act, collaborate, and improve themselves.I just shared a new blog post where I dive into one of the most exciting parts of the journey:Designing autonomous planning and decision-making AI solutions.Check it out here: üß† Think, Plan, Solve: A Smarter Way to Tackle Problems with Multi-Agent Planning https://lnkd.in/g_ne9teQLet‚Äôs build smarter agents, stronger teams, and shape what‚Äôs next.If you‚Äôre working with agentic systems, I‚Äôd love to hear what excites you most!hashtag#AI hashtag#AgenticAI hashtag#AutonomousAgents hashtag#MultiAgentSystems hashtag#LLM hashtag#AIInnovation hashtag#FutureOfWork hashtag#AICommunity hashtag#opensource hashtag#IBM hashtag#MachineLearning hashtag#PromptEngineering', \"üí° How does ChatGPT process your questions behind the scenes?Have you ever wondered if there's an agentic AI solution that can: ‚ñ´Ô∏è Take a task from the user ‚ñ´Ô∏è Plan and assign a list of agents and tasks behind the scenes ‚ñ´Ô∏è Work step-by-step to solve complex problems intelligently?Sounds a lot like how ChatGPT thinks, plans, and solves ‚Äî right? üîÅIn my latest blog post, I introduce: üß† Think, Plan, Solve: A Smarter Way to Tackle Problems with Multi-Agent PlanningUsing open source hashtag#LLMs, hashtag#CrewAI and hashtag#Ollama, I built a system that: ‚úÖ Takes any user-defined goal ‚úÖ Breaks it down into a sequence of actionable tasks ‚úÖ Automatically architects a list of agents and tasks, saving them in YAML format ‚úÖ Dynamically assigns agents using the YAML configuration ‚úÖ Solves it recursively and adaptively ‚Äî like an autonomous team of thinkersüìñ Check out the blog: üëâ https://lnkd.in/g_ne9teQWould love to hear your thoughts and ideas! hashtag#AI hashtag#ThinkPlanSolve hashtag#MultiAgentSystems hashtag#LLM hashtag#AutonomousAgents hashtag#PromptEngineering hashtag#OpenSource hashtag#GenerativeAI hashtag#BeeAIP.S. While this version uses CrewAI, the concept is flexible ‚Äî you can use any multi-agent platform. I'm planning to try it next with BEEAI üëÄ Stay tuned!\"]\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mLinkedIn Post Scraper\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "```json\n",
      "[\n",
      "    \"Climbing the AI Agents Staircase ‚Äì One Step Closer to the Future!Every day, I get more fired up about what‚Äôs possible with Agentic AI! From simple LLMs to fully autonomous systems capable of planning, decision-making, and even self-learning‚Äîthis is the frontier of innovation, and we‚Äôre right in the thick of it.This awesome visual below breaks it all down‚Äîfrom the basics to the advanced, showing how we move from connecting APIs and memory management‚Ä¶ all the way up to agents that can think, act, collaborate, and improve themselves.I just shared a new blog post where I dive into one of the most exciting parts of the journey:Designing autonomous planning and decision-making AI solutions.Check it out here: üß† Think, Plan, Solve: A Smarter Way to Tackle Problems with Multi-Agent Planning https://lnkd.in/g_ne9teQLet‚Äôs build smarter agents, stronger teams, and shape what‚Äôs next.If you‚Äôre working with agentic systems, I‚Äôd love to hear what excites you most!hashtag#AI hashtag#AgenticAI hashtag#AutonomousAgents hashtag#MultiAgentSystems hashtag#LLM hashtag#AIInnovation hashtag#FutureOfWork hashtag#AICommunity hashtag#opensource hashtag#IBM hashtag#MachineLearning hashtag#PromptEngineering\",\n",
      "    \"üí° How does ChatGPT process your questions behind the scenes?Have you ever wondered if there's an agentic AI solution that can: ‚ñ´Ô∏è Take a task from the user ‚ñ´Ô∏è Plan and assign a list of agents and tasks behind the scenes ‚ñ´Ô∏è Work step-by-step to solve complex problems intelligently?Sounds a lot like how ChatGPT thinks, plans, and solves ‚Äî right? üîÅIn my latest blog post, I introduce: üß† Think, Plan, Solve: A Smarter Way to Tackle Problems with Multi-Agent PlanningUsing open source hashtag#LLMs, hashtag#CrewAI and hashtag#Ollama, I built a system that: ‚úÖ Takes any user-defined goal ‚úÖ Breaks it down into a sequence of actionable tasks ‚úÖ Automatically architects a list of agents and tasks, saving them in YAML format ‚úÖ Dynamically assigns agents using the YAML configuration ‚úÖ Solves it recursively and adaptively ‚Äî like an autonomous team of thinkersüìñ Check out the blog: üëâ https://lnkd.in/g_ne9teQWould love to hear your thoughts and ideas! hashtag#AI hashtag#ThinkPlanSolve hashtag#MultiAgentSystems hashtag#LLM hashtag#AutonomousAgents hashtag#PromptEngineering hashtag#OpenSource hashtag#GenerativeAI hashtag#BeeAIP.S. While this version uses CrewAI, the concept is flexible ‚Äî you can use any multi-agent platform. I'm planning to try it next with BEEAI üëÄ Stay tuned!\"\n",
      "]\n",
      "```\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mWeb Researcher\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mGet valuable and high quality web information about the comparison between Llama 2 and Llama 3\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mWeb Researcher\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mI need to search for relevant content about the comparison between Llama 2 and Llama 3.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mSearch the internet with Serper\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"search_query\\\": \\\"Comparison between Llama 2 and Llama 3\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "{'searchParameters': {'q': 'Comparison between Llama 2 and Llama 3', 'type': 'search', 'num': 10, 'engine': 'google'}, 'organic': [{'title': 'Llama 2 vs Llama 3: An In-depth Comparison - Medium', 'link': 'https://medium.com/@vineethveetil/llama-2-vs-llama-3-an-in-depth-comparison-aebb6a3f8c51', 'snippet': \"Llama 2 uses SentencePiece for tokenization, whereas Llama 3 has transitioned to OpenAI's Tiktoken. Llama 3 also introduces a ChatFormat class, ...\", 'position': 1}, {'title': \"Meta's Llama 2 Vs Llama 3: What's New and Why It Matters - Kanerika\", 'link': 'https://kanerika.com/blogs/llama-3-vs-llama-2/', 'snippet': 'Llama 3 is often more efficient than Llama 2, requiring fewer computational resources to achieve similar results. While both models can be run ...', 'position': 2, 'sitelinks': [{'title': 'Llama 2 vs Llama 3...', 'link': 'https://kanerika.com/blogs/llama-3-vs-llama-2/#h-llama-2-vs-llama-3-understanding-meta-s-llama-models'}, {'title': 'Llama 2 vs Llama 3: A...', 'link': 'https://kanerika.com/blogs/llama-3-vs-llama-2/#h-llama-2-vs-llama-3-a-detailed-comparison-nbsp'}, {'title': 'Llama 2 vs Llama 3: Key...', 'link': 'https://kanerika.com/blogs/llama-3-vs-llama-2/#h-llama-2-vs-llama-3-key-differences'}]}, {'title': 'Llama 3 vs Llama 2. Comparison, Differences, Features | Apps4Rent', 'link': 'https://www.apps4rent.com/blog/llama-3-vs-llama-2/', 'snippet': 'Llama 3 has made some big improvements compared to Llama 2. Llama 3 8B contains 8 billion parameters and Llama 3 70B contains 70 billion parameters.', 'position': 3}, {'title': 'why is llama 3 better than llama 2? | Compare top AI models side-by ...', 'link': 'https://sdk.vercel.ai/playground/s/1xHwT24LxGNEpeFW7YF9k', 'snippet': \"Larger model size: LLaMA 3 has a larger model size, with 13 billion parameters, compared to LLaMA 2's 8 billion parameters. This allows LLaMA 3 to learn more ...\", 'position': 4}, {'title': 'Introducing Meta Llama 3: The most capable openly available LLM ...', 'link': 'https://ai.meta.com/blog/meta-llama-3/', 'snippet': 'Our benchmarks show the tokenizer offers improved token efficiency, yielding up to 15% fewer tokens compared to Llama 2. Also, Group Query ...', 'position': 5}, {'title': \"I'd Rather have Llama-2 with 65K+ Context Size than Llama-3 or ...\", 'link': 'https://www.reddit.com/r/LocalLLaMA/comments/1dq5lia/id_rather_have_llama2_with_65k_context_size_than/', 'snippet': 'LLaMa had a context length of 2048, then Llama-2 had 4096, now Llama-3 has 8192. Fine tuning with RoPE scaling is a lot cheaper and less ...', 'position': 6}, {'title': 'Differences Between LLAMA 2 and LLAMA 3 - LinkedIn', 'link': 'https://www.linkedin.com/pulse/differences-between-llama-2-3-blockchaincouncil-to3jc', 'snippet': \"LLAMA 3 features a more efficient tokenizer with a vocabulary size of 128K tokens, compared to LLAMA 2's smaller tokenizer. This improvement ...\", 'position': 7}, {'title': 'Result: Llama 3 EXL2 quant quality compared to GGUF and Llama 2', 'link': 'https://www.reddit.com/r/LocalLLaMA/comments/1cfbadc/result_llama_3_exl2_quant_quality_compared_to/', 'snippet': 'The quality at same model size seems to be exactly the same between EXL2 and the latest imatrix IQ quants of GGUF, for both Llama 3 and 2.', 'position': 8}, {'title': 'Llama 2 vs Llama 3: Key AI Model Comparisons & Insights', 'link': 'https://www.neuronimbus.com/blog/a-comparative-analysis-and-the-ultimate-comparison-of-all-large-language-models/', 'snippet': 'Llama 2 was trained on 2 trillion tokens, offering a strong foundation for general tasks. Llama 3, however, steps ahead with 15 trillion tokens, ...', 'position': 9}, {'title': \"What is Meta's Llama 3 and comparison with llama 2? - Hamid Ayub\", 'link': 'https://hamidayub.medium.com/what-is-metas-llama-3-and-comparison-with-llama-2-0de992430e3c', 'snippet': 'This article explores the enhancements introduced with Llama 3, its impact on various sectors, and provides a detailed comparison with Llama 2.', 'position': 10, 'sitelinks': [{'title': 'Reactjs & Machine Learning...', 'link': 'https://hamidayub.medium.com/what-is-metas-llama-3-and-comparison-with-llama-2-0de992430e3c#:~:text=Reactjs%20%26%20Machine%20learning%20%2D%2D%20Your%20First%20Project,-Beginner%20Level%3A%20An%20Introduction'}, {'title': 'Gpt-4o: Successor Of Gpt-4?', 'link': 'https://hamidayub.medium.com/what-is-metas-llama-3-and-comparison-with-llama-2-0de992430e3c#:~:text=GPT%2D4o%3A%20Successor%20of%20GPT%2D4%3F,-The%20world%20of%20artificial%20intelligence'}, {'title': 'Python Mastery In 30 Day', 'link': 'https://hamidayub.medium.com/what-is-metas-llama-3-and-comparison-with-llama-2-0de992430e3c#:~:text=Python%20Mastery%20in%2030%20Day,-A%20guideline%20based%20on%20my'}]}], 'peopleAlsoAsk': [{'question': 'How is llama 3 different from llama 2?', 'snippet': 'While Llama 2, launched in 2023, revolutionized how developers work with language models, Llama 3 takes it a step further with improved response accuracy, greater diversity, and enhanced reasoning.\\nSep 13, 2024', 'title': \"Meta's Llama 2 Vs Llama 3: What's New and Why It Matters - Kanerika\", 'link': 'https://kanerika.com/blogs/llama-3-vs-llama-2/'}, {'question': 'What is the difference between llama 2 and 3 tokenizer?', 'snippet': \"LLAMA 3 features a more efficient tokenizer with a vocabulary size of 128K tokens, compared to LLAMA 2's smaller tokenizer. This improvement enhances the model's ability to encode language and boosts overall performance.\\nAug 8, 2024\", 'title': 'Differences Between LLAMA 2 and LLAMA 3 - LinkedIn', 'link': 'https://www.linkedin.com/pulse/differences-between-llama-2-3-blockchaincouncil-to3jc'}, {'question': 'What is llama 3 used for?', 'snippet': 'Content creation: By using Llama 3, you can generate different types of content, varying from articles and reports to blogs and even stories. This way, you streamline the content creation process and churn out more pieces faster.', 'title': \"What is Llama 3? Beginner's Step-by-Step Guide [2025] - Guru\", 'link': 'https://www.getguru.com/reference/what-is-llama-3'}, {'question': 'Is llama 2 better than gpt 4?', 'snippet': 'GPT-4 Performance Metrics: GPT-4 consistently outperforms Llama 2 across various benchmark scores, including the HumanEval (coding) benchmark, where it significantly surpasses Llama 2 in coding skills. This highlights its superior performance in specific tasks, especially mathematical and reasoning tasks.', 'title': 'Llama 2 vs GPT 4: Key Differences Explained - Labellerr', 'link': 'https://www.labellerr.com/blog/9-key-differences-between-gpt4-and-llama2-you-should-know/'}], 'relatedSearches': [{'query': 'Llama vs Llama 2 architecture'}, {'query': 'Difference between Llama and Llama 2'}, {'query': 'Llama 3 8B vs Llama 2 13B'}, {'query': 'Llama 2 release date'}, {'query': 'Llama 2 parameters'}, {'query': 'How to use Llama 3'}, {'query': 'Llama 2 paper'}, {'query': 'Is Llama 3 free'}], 'credits': 1}\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mWeb Researcher\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "Llama 3 is an advanced language model developed by Meta that builds upon the capabilities of its predecessor, Llama 2. Here are some key differences and improvements in Llama 3 compared to Llama 2:\n",
      "\n",
      "1. **Improved Response Accuracy**: Llama 3 offers enhanced response accuracy, making it more reliable for a wide range of applications.\n",
      "\n",
      "2. **Greater Diversity**: The model provides greater diversity in its responses, allowing for more creative and varied outputs.\n",
      "\n",
      "3. **Enhanced Reasoning**: Llama 3 has improved reasoning capabilities, enabling it to handle complex tasks more effectively.\n",
      "\n",
      "4. **Tokenizer Efficiency**: Llama 3 features a more efficient tokenizer with a vocabulary size of 128K tokens, compared to Llama 2's smaller tokenizer. This improvement enhances the model's ability to encode language and boosts overall performance [REF]peopleAlsoAsk[/REF].\n",
      "\n",
      "5. **Context Window**: Llama 3 has an increased context window, allowing it to process and generate longer sequences of text more effectively.\n",
      "\n",
      "6. **Training Data**: Llama 3 has been trained on a larger and more diverse dataset, which contributes to its improved performance and versatility.\n",
      "\n",
      "7. **Use Cases**: Llama 3 can be used for various applications, including content creation, generating articles, reports, blogs, and even stories. This streamlines the content creation process and allows for faster production of high-quality content [REF]peopleAlsoAsk[/REF].\n",
      "\n",
      "These enhancements make Llama 3 a more powerful and versatile tool for developers and users working with language models.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mLinkedIn Post Creator\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mCreate a LinkedIn post comparing Llama 2 and Llama 3 following the writing-style expressed in the scraped LinkedIn posts.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mLinkedIn Post Creator\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "üí° **Unlocking the Future: Llama 2 vs. Llama 3 ‚Äì A Leap Forward in AI!**\n",
      "\n",
      "Every day, I get more excited about what‚Äôs possible with advanced language models like Llama 2 and its successor, Llama 3! From simple LLMs to fully autonomous systems capable of planning, decision-making, and even self-learning‚Äîthis is the frontier of innovation, and we‚Äôre right in the thick of it.\n",
      "\n",
      "Let's dive into how Llama 3 builds upon the capabilities of Llama 2:\n",
      "\n",
      "1. **Improved Response Accuracy**: Llama 3 offers enhanced response accuracy, making it more reliable for a wide range of applications. This means you can trust it to deliver precise and relevant information every time.\n",
      "\n",
      "2. **Greater Diversity**: The model provides greater diversity in its responses, allowing for more creative and varied outputs. Whether you need content creation or brainstorming ideas, Llama 3 has got you covered!\n",
      "\n",
      "3. **Enhanced Reasoning**: Llama 3 has improved reasoning capabilities, enabling it to handle complex tasks more effectively. This makes it an invaluable tool for problem-solving and decision-making.\n",
      "\n",
      "4. **Tokenizer Efficiency**: Llama 3 features a more efficient tokenizer with a vocabulary size of 128K tokens, compared to Llama 2's smaller tokenizer. This improvement enhances the model's ability to encode language and boosts overall performance.\n",
      "\n",
      "5. **Context Window**: Llama 3 has an increased context window, allowing it to process and generate longer sequences of text more effectively. This is perfect for tasks that require understanding and generating lengthy content.\n",
      "\n",
      "6. **Training Data**: Llama 3 has been trained on a larger and more diverse dataset, which contributes to its improved performance and versatility. The more data it learns from, the better it gets!\n",
      "\n",
      "7. **Use Cases**: Llama 3 can be used for various applications, including content creation, generating articles, reports, blogs, and even stories. This streamlines the content creation process and allows for faster production of high-quality content.\n",
      "\n",
      "These enhancements make Llama 3 a more powerful and versatile tool for developers and users working with language models. It's an exciting time to be in AI, and I can't wait to see what innovations come next!\n",
      "\n",
      "If you‚Äôre working with these models or have ideas on how they can be used, I‚Äôd love to hear from you! Let‚Äôs build smarter systems and shape the future together.\n",
      "\n",
      "#AI #Llama2 #Llama3 #LanguageModels #AIInnovation #FutureOfWork #AICommunity #MachineLearning #ContentCreation\u001b[00m\n",
      "\n",
      "\n",
      "Here is the result: \n",
      "üí° **Unlocking the Future: Llama 2 vs. Llama 3 ‚Äì A Leap Forward in AI!**\n",
      "\n",
      "Every day, I get more excited about what‚Äôs possible with advanced language models like Llama 2 and its successor, Llama 3! From simple LLMs to fully autonomous systems capable of planning, decision-making, and even self-learning‚Äîthis is the frontier of innovation, and we‚Äôre right in the thick of it.\n",
      "\n",
      "Let's dive into how Llama 3 builds upon the capabilities of Llama 2:\n",
      "\n",
      "1. **Improved Response Accuracy**: Llama 3 offers enhanced response accuracy, making it more reliable for a wide range of applications. This means you can trust it to deliver precise and relevant information every time.\n",
      "\n",
      "2. **Greater Diversity**: The model provides greater diversity in its responses, allowing for more creative and varied outputs. Whether you need content creation or brainstorming ideas, Llama 3 has got you covered!\n",
      "\n",
      "3. **Enhanced Reasoning**: Llama 3 has improved reasoning capabilities, enabling it to handle complex tasks more effectively. This makes it an invaluable tool for problem-solving and decision-making.\n",
      "\n",
      "4. **Tokenizer Efficiency**: Llama 3 features a more efficient tokenizer with a vocabulary size of 128K tokens, compared to Llama 2's smaller tokenizer. This improvement enhances the model's ability to encode language and boosts overall performance.\n",
      "\n",
      "5. **Context Window**: Llama 3 has an increased context window, allowing it to process and generate longer sequences of text more effectively. This is perfect for tasks that require understanding and generating lengthy content.\n",
      "\n",
      "6. **Training Data**: Llama 3 has been trained on a larger and more diverse dataset, which contributes to its improved performance and versatility. The more data it learns from, the better it gets!\n",
      "\n",
      "7. **Use Cases**: Llama 3 can be used for various applications, including content creation, generating articles, reports, blogs, and even stories. This streamlines the content creation process and allows for faster production of high-quality content.\n",
      "\n",
      "These enhancements make Llama 3 a more powerful and versatile tool for developers and users working with language models. It's an exciting time to be in AI, and I can't wait to see what innovations come next!\n",
      "\n",
      "If you‚Äôre working with these models or have ideas on how they can be used, I‚Äôd love to hear from you! Let‚Äôs build smarter systems and shape the future together.\n",
      "\n",
      "#AI #Llama2 #Llama3 #LanguageModels #AIInnovation #FutureOfWork #AICommunity #MachineLearning #ContentCreation\n"
     ]
    }
   ],
   "source": [
    "from crewai import Crew\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from agents import linkedin_scraper_agent, web_researcher_agent, doppelganger_agent\n",
    "from tasks import scrape_linkedin_task, web_research_task, create_linkedin_post_task\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "crew = Crew(\n",
    "    agents=[\n",
    "        linkedin_scraper_agent,\n",
    "        web_researcher_agent,\n",
    "        doppelganger_agent\n",
    "    ],\n",
    "    tasks=[\n",
    "        scrape_linkedin_task,\n",
    "        web_research_task,\n",
    "        create_linkedin_post_task\n",
    "    ]\n",
    ")\n",
    "\n",
    "result = crew.kickoff()\n",
    "\n",
    "\n",
    "print(\"Here is the result: \")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b5b0a13-15ee-4daa-aa1d-f63eaae9e64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                             ID              SIZE      MODIFIED     \n",
      "hf.co/unsloth/Mistral-Small-3.1-24B-Instruct-2503-GGUF:Q5_K_M    73cf47fe711c    16 GB     11 days ago     \n",
      "exaone-deep:latest                                               106afe416a9e    4.8 GB    2 weeks ago     \n",
      "hf.co/bartowski/open-r1_OlympicCoder-32B-GGUF:Q4_K_S             e849518c3f59    18 GB     2 weeks ago     \n",
      "llama3.2:3b-beeai                                                c3bc94496dab    2.0 GB    2 weeks ago     \n",
      "phi4-mini:3.8b-fp16                                              d40845b9e3a0    7.7 GB    2 weeks ago     \n",
      "gemma3:27b                                                       30ddded7fba6    17 GB     3 weeks ago     \n",
      "gemma3:12b                                                       6fd036cefda5    8.1 GB    3 weeks ago     \n",
      "qwq:latest                                                       cc1091b0e276    19 GB     3 weeks ago     \n",
      "hf.co/OuteAI/OuteTTS-0.3-500M-GGUF:Q4_K_S                        76c6be93d29c    391 MB    4 weeks ago     \n",
      "hf.co/OuteAI/OuteTTS-0.2-500M-GGUF:Q8_0                          0a6c38a67073    536 MB    4 weeks ago     \n",
      "mistral-small:24b                                                8039dd90c113    14 GB     4 weeks ago     \n",
      "llama3.2-vision:11b                                              085a1fdae525    7.9 GB    4 weeks ago     \n",
      "mistral-nemo:latest                                              994f3b8b7801    7.1 GB    4 weeks ago     \n",
      "granite3.2:8b                                                    9bcb3335083f    4.9 GB    5 weeks ago     \n",
      "granite3.2-vision:latest                                         3be41a661804    2.4 GB    5 weeks ago     \n",
      "phi4:latest                                                      ac896e5b8b34    9.1 GB    6 weeks ago     \n",
      "nomic-embed-text:latest                                          0a109f422b47    274 MB    6 weeks ago     \n",
      "llama3.2:3b                                                      a80c4f17acd5    2.0 GB    2 months ago    \n",
      "hf.co/lmstudio-community/Qwen2.5-7B-Instruct-1M-GGUF:Q8_0        2d4b678222de    8.1 GB    2 months ago    \n",
      "mxbai-embed-large:latest                                         468836162de7    669 MB    4 months ago    \n",
      "llama3.2:1b                                                      baf6a787fdff    1.3 GB    5 months ago    \n"
     ]
    }
   ],
   "source": [
    "!Ollama list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6677f2e7-052f-457b-8434-7eff0256080b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter your topic (e.g., 'Llama 3 vs Llama 2'):  mcp server and its influnce in Agentic AI\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mLinkedIn Post Scraper\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mScrape a LinkedIn profile to get relevant posts.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mLinkedIn Post Scraper\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mScrapeLinkedinPosts\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "['Climbing the AI Agents Staircase ‚Äì One Step Closer to the Future!Every day, I get more fired up about what‚Äôs possible with Agentic AI! From simple LLMs to fully autonomous systems capable of planning, decision-making, and even self-learning‚Äîthis is the frontier of innovation, and we‚Äôre right in the thick of it.This awesome visual below breaks it all down‚Äîfrom the basics to the advanced, showing how we move from connecting APIs and memory management‚Ä¶ all the way up to agents that can think, act, collaborate, and improve themselves.I just shared a new blog post where I dive into one of the most exciting parts of the journey:Designing autonomous planning and decision-making AI solutions.Check it out here: üß† Think, Plan, Solve: A Smarter Way to Tackle Problems with Multi-Agent Planning https://lnkd.in/g_ne9teQLet‚Äôs build smarter agents, stronger teams, and shape what‚Äôs next.If you‚Äôre working with agentic systems, I‚Äôd love to hear what excites you most!hashtag#AI hashtag#AgenticAI hashtag#AutonomousAgents hashtag#MultiAgentSystems hashtag#LLM hashtag#AIInnovation hashtag#FutureOfWork hashtag#AICommunity hashtag#opensource hashtag#IBM hashtag#MachineLearning hashtag#PromptEngineering', \"üí° How does ChatGPT process your questions behind the scenes?Have you ever wondered if there's an agentic AI solution that can: ‚ñ´Ô∏è Take a task from the user ‚ñ´Ô∏è Plan and assign a list of agents and tasks behind the scenes ‚ñ´Ô∏è Work step-by-step to solve complex problems intelligently?Sounds a lot like how ChatGPT thinks, plans, and solves ‚Äî right? üîÅIn my latest blog post, I introduce: üß† Think, Plan, Solve: A Smarter Way to Tackle Problems with Multi-Agent PlanningUsing open source hashtag#LLMs, hashtag#CrewAI and hashtag#Ollama, I built a system that: ‚úÖ Takes any user-defined goal ‚úÖ Breaks it down into a sequence of actionable tasks ‚úÖ Automatically architects a list of agents and tasks, saving them in YAML format ‚úÖ Dynamically assigns agents using the YAML configuration ‚úÖ Solves it recursively and adaptively ‚Äî like an autonomous team of thinkersüìñ Check out the blog: üëâ https://lnkd.in/g_ne9teQWould love to hear your thoughts and ideas! hashtag#AI hashtag#ThinkPlanSolve hashtag#MultiAgentSystems hashtag#LLM hashtag#AutonomousAgents hashtag#PromptEngineering hashtag#OpenSource hashtag#GenerativeAI hashtag#BeeAIP.S. While this version uses CrewAI, the concept is flexible ‚Äî you can use any multi-agent platform. I'm planning to try it next with BEEAI üëÄ Stay tuned!\"]\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mLinkedIn Post Scraper\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "1. Climbing the AI Agents Staircase ‚Äì One Step Closer to the Future!\n",
      "\n",
      "Every day, I get more fired up about what‚Äôs possible with Agentic AI! From simple LLMs to fully autonomous systems capable of planning, decision-making, and even self-learning‚Äîthis is the frontier of innovation, and we‚Äôre right in the thick of it.\n",
      "\n",
      "This awesome visual below breaks it all down‚Äîfrom the basics to the advanced, showing how we move from connecting APIs and memory management‚Ä¶ all the way up to agents that can think, act, collaborate, and improve themselves.\n",
      "\n",
      "I just shared a new blog post where I dive into one of the most exciting parts of the journey: Designing autonomous planning and decision-making AI solutions. Check it out here:\n",
      "\n",
      "üß† Think, Plan, Solve: A Smarter Way to Tackle Problems with Multi-Agent Planning\n",
      "https://lnkd.in/g_ne9teQ\n",
      "\n",
      "Let‚Äôs build smarter agents, stronger teams, and shape what‚Äôs next.\n",
      "\n",
      "If you‚Äôre working with agentic systems, I‚Äôd love to hear what excites you most!\n",
      "\n",
      "#AI #AgenticAI #AutonomousAgents #MultiAgentSystems #LLM #AIInnovation #FutureOfWork #AICommunity #opensource #IBM #MachineLearning #PromptEngineering\n",
      "\n",
      "2. üí° How does ChatGPT process your questions behind the scenes?\n",
      "\n",
      "Have you ever wondered if there's an agentic AI solution that can:\n",
      "\n",
      "‚ñ´Ô∏è Take a task from the user\n",
      "‚ñ´Ô∏è Plan and assign a list of agents and tasks behind the scenes\n",
      "‚ñ´Ô∏è Work step-by-step to solve complex problems intelligently?\n",
      "\n",
      "Sounds a lot like how ChatGPT thinks, plans, and solves ‚Äî right? üîÅ\n",
      "\n",
      "In my latest blog post, I introduce:\n",
      "\n",
      "üß† Think, Plan, Solve: A Smarter Way to Tackle Problems with Multi-Agent Planning\n",
      "\n",
      "Using open source #LLMs, #CrewAI and #Ollama, I built a system that:\n",
      "\n",
      "‚úÖ Takes any user-defined goal\n",
      "‚úÖ Breaks it down into a sequence of actionable tasks\n",
      "‚úÖ Automatically architects a list of agents and tasks, saving them in YAML format\n",
      "‚úÖ Dynamically assigns agents using the YAML configuration\n",
      "‚úÖ Solves it recursively and adaptively ‚Äî like an autonomous team of thinkers\n",
      "\n",
      "üìñ Check out the blog: üëâ https://lnkd.in/g_ne9teQ\n",
      "\n",
      "Would love to hear your thoughts and ideas!\n",
      "\n",
      "#AI #ThinkPlanSolve #MultiAgentSystems #LLM #AutonomousAgents #PromptEngineering #OpenSource #GenerativeAI #BeeAIP.\n",
      "\n",
      "P.S. While this version uses CrewAI, the concept is flexible ‚Äî you can use any multi-agent platform. I'm planning to try it next with BEEAI üëÄ Stay tuned!\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mWeb Researcher\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mResearch the topic \"mcp server and its influnce in Agentic AI\" for trends, comparisons, and news.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mWeb Researcher\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mI need to start by searching for relevant information about \"mcp server\" and its influence in Agentic AI. I will begin with a general search to gather initial data.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mSearch the internet with Serper\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"search_query\\\": \\\"mcp server and its influnce in Agentic AI\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "{'searchParameters': {'q': 'mcp server and its influnce in Agentic AI', 'type': 'search', 'num': 10, 'engine': 'google'}, 'organic': [{'title': 'Will Model Context Protocol (MCP) Become the Standard for Agentic ...', 'link': 'https://www.bigdatawire.com/2025/03/31/will-model-context-protocol-mcp-become-the-standard-for-agentic-ai/', 'snippet': 'Anthropic designed MCP as a lightweight architecture to enable developers to build secure, two-way connections between the MCP server (data ...', 'position': 1}, {'title': 'MCP Servers: The Apps of the Agentic AI Age? And Why Security ...', 'link': 'https://kloudle.com/blog/mcp-servers-apps-of-agentic-age/', 'snippet': 'What are MCP Servers and why does their introduction impact security configurations?', 'position': 2}, {'title': 'From AI Agents to Agentic AI to MCP Servers - LinkedIn', 'link': 'https://www.linkedin.com/pulse/from-ai-agents-agentic-mcp-servers-revolutionizing-automation-verma-5kyxc', 'snippet': \"Here's how MCP servers enhance the capabilities of agentic AI: Dynamic Data Retrieval: MCP servers allow AI agents to query external data ...\", 'position': 3}, {'title': 'MCP Servers [Explained] Python and Agentic AI Tool Integration', 'link': 'https://medium.com/@simranjeetsingh1497/mcp-servers-explained-python-and-agentic-ai-tool-integration-aa2ddca6cbe5', 'snippet': 'At its core, MCP serves as a bridge between AI models and the outside world. It enables AI systems to: Query different data sources using a ...', 'position': 4}, {'title': 'Introducing the Model Context Protocol - Anthropic', 'link': 'https://www.anthropic.com/news/model-context-protocol', 'snippet': 'The Model Context Protocol is an open standard that enables developers to build secure, two-way connections between their data sources and AI-powered tools.', 'position': 5}, {'title': 'Introducing AWS MCP Servers for code assistants (Part 1)', 'link': 'https://aws.amazon.com/blogs/machine-learning/introducing-aws-mcp-servers-for-code-assistants-part-1/', 'snippet': 'Our specialized AWS MCP servers combine deep AWS knowledge with agentic AI capabilities to accelerate development across key areas. Each AWS MCP ...', 'position': 6}, {'title': 'Fully Featured AI Coding Agent as MCP Server : r/ClaudeAI - Reddit', 'link': 'https://www.reddit.com/r/ClaudeAI/comments/1jpavtm/fully_featured_ai_coding_agent_as_mcp_server/', 'snippet': 'It can run as an MCP server, so you can use it for free with Claude Desktop, and it can still fully understand a code base, even a very large ...', 'position': 7}, {'title': 'Model Context Protocol (MCP): Hands-On with Agentic AI', 'link': 'https://career.cornell.edu/classes/model-context-protocol-mcp-hands-on-with-agentic-ai/', 'snippet': 'MCP servers expose resources (data), tools (actions), and prompts (instructions) for the LLM and the user to use in performing more complex operations. In ...', 'position': 8}, {'title': 'MCP: The Universal Connector Revolutionizing AI Agent Development', 'link': 'https://medium.com/@nomannayeem/mcp-the-universal-connector-revolutionizing-ai-agent-development-1cf990fc339f', 'snippet': 'MCP Server: These lightweight servers expose specific functionalities via MCP, connecting directly to local data sources such as databases, APIs ...', 'position': 9}], 'relatedSearches': [{'query': 'Mcp server and its influence in agentic ai ppt'}, {'query': 'Mcp server and its influence in agentic ai github'}], 'credits': 1}\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mWeb Researcher\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mThought: I will read the content of the top search results to gather detailed information about MCP servers and their role in Agentic AI.\n",
      "Action: Search the internet with Serper\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mSearch the internet with Serper\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"search_query\\\": \\\"MCP Servers: The Apps of the Agentic AI Age? And Why Security\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "{'searchParameters': {'q': 'MCP Servers: The Apps of the Agentic AI Age? And Why Security', 'type': 'search', 'num': 10, 'engine': 'google'}, 'organic': [{'title': 'MCP Servers: The Apps of the Agentic AI Age? And Why Security ...', 'link': 'https://kloudle.com/blog/mcp-servers-apps-of-agentic-age/', 'snippet': 'Essentially, MCP provides a standardized interface for AI agents to discover and securely interact with external tools and functions. Instead of ...', 'position': 1}, {'title': 'Everything You Need to Know about MCP Servers, Explained', 'link': 'https://sebastian-petrus.medium.com/everything-you-need-to-know-about-mcp-servers-explained-b434d11e763e', 'snippet': 'The Model Context Protocol (MCP) has revolutionized how AI systems interact with real-world data and resources.', 'position': 2}, {'title': '#cloudsecurity #agentic #aisecurity #mcpservers | Akash Mahajan ...', 'link': 'https://www.linkedin.com/posts/akashm_cloudsecurity-agentic-aisecurity-activity-7311405281949667330-G4nt', 'snippet': 'MCP Servers: Are These the \"Apps\" of the Agentic AI Age? And Why Security Needs to Catch Up NOW Remember the cloud evolution? 1.', 'position': 3}, {'title': 'A Deep Dive Into MCP and the Future of AI Tooling', 'link': 'https://a16z.com/a-deep-dive-into-mcp-and-the-future-of-ai-tooling/', 'snippet': \"MCP is an open protocol that allows systems to provide context to AI models in a manner that's generalizable across integrations. The protocol ...\", 'position': 4}, {'title': 'MCP Server Security: The Key to Agentic AI Interoperability, But Are ...', 'link': 'https://levelup.gitconnected.com/mcp-server-security-b97264388076', 'snippet': 'Discover the crucial role of MCP servers in orchestrating GenAI Agents and the potential security risks lurking beneath the surface.', 'position': 5}, {'title': 'MCP: The missing link for agentic AI? - Runtime', 'link': 'https://www.runtime.news/mcp-the-missing-link-for-agentic-ai/', 'snippet': 'The protocol takes natural language input from a large-language model and provides a standard way for MCP clients (apps running on your laptop ...', 'position': 6}, {'title': \"OpenAI's support puts MCP in pole position as agentic AI standard\", 'link': 'https://www.constellationr.com/blog-news/insights/openais-support-puts-mcp-pole-position-agentic-ai-standard', 'snippet': 'Microsoft is also supporting MCP and launched a new Playwright-MCP server that enables AI agents to browse the web and interact with sites.', 'position': 7}, {'title': 'MCP: What It Is and Why It Matters - Elevate | Addy Osmani - Substack', 'link': 'https://addyo.substack.com/p/mcp-what-it-is-and-why-it-matters', 'snippet': 'Essentially, the protocol ensures that whether an AI is talking to a design tool or a database, the handshake and query format are consistent.', 'position': 8}, {'title': \"To MCP or Not to MCP Part 1: A Critical Analysis of Anthropic's ...\", 'link': 'https://medium.com/@sanjmo/to-mcp-or-not-to-mcp-part-1-a-critical-analysis-of-anthropics-model-context-protocol-571a51cb9f05', 'snippet': 'MCP mimics what we have traditionally known and operated (a classical client-server model) where AI applications act as client and controller, ...', 'position': 9, 'sitelinks': [{'title': 'Custom Tools / Agent...', 'link': 'https://medium.com/@sanjmo/to-mcp-or-not-to-mcp-part-1-a-critical-analysis-of-anthropics-model-context-protocol-571a51cb9f05#:~:text=Custom%20Tools%20%2F%20Agent%20Framework%20and%20no%20MCP'}, {'title': 'Mcp Compliant Server / Proxy', 'link': 'https://medium.com/@sanjmo/to-mcp-or-not-to-mcp-part-1-a-critical-analysis-of-anthropics-model-context-protocol-571a51cb9f05#:~:text=MCP%20Compliant%20Server%20%2F%20Proxy,-An%20MCP%20compliant%20Server%20or'}, {'title': 'Hybrid Agent / Tools...', 'link': 'https://medium.com/@sanjmo/to-mcp-or-not-to-mcp-part-1-a-critical-analysis-of-anthropics-model-context-protocol-571a51cb9f05#:~:text=Hybrid%20Agent%20%2F%20Tools%20Framework%20with%20MCP,-Use%20agent%20%2F%20tools%20framework'}]}, {'title': 'Harness the power of MCP servers with Amazon Bedrock Agents', 'link': 'https://aws.amazon.com/blogs/machine-learning/harness-the-power-of-mcp-servers-with-amazon-bedrock-agents/', 'snippet': 'Using a client-server architecture, MCP enables developers to expose their data through lightweight MCP servers while building AI applications ...', 'position': 10, 'sitelinks': [{'title': 'Model Context Protocol', 'link': 'https://aws.amazon.com/blogs/machine-learning/harness-the-power-of-mcp-servers-with-amazon-bedrock-agents/#:~:text=Model%20Context%20Protocol,-Developed%20by%20Anthropic%20as%20an'}, {'title': 'Steps To Run', 'link': 'https://aws.amazon.com/blogs/machine-learning/harness-the-power-of-mcp-servers-with-amazon-bedrock-agents/#:~:text=Steps%20to%20run'}, {'title': 'Implementation Details', 'link': 'https://aws.amazon.com/blogs/machine-learning/harness-the-power-of-mcp-servers-with-amazon-bedrock-agents/#:~:text=Implementation%20details'}]}], 'credits': 1}\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mWeb Researcher\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "MCP (Model Context Protocol) is an emerging standard in the field of agentic AI, designed to facilitate communication between AI models and various tools or services. Here‚Äôs a comprehensive overview:\n",
      "\n",
      "1. **Definition and Purpose**:\n",
      "   - MCP is a protocol developed by Anthropic that enables AI applications to interact with external tools and services in a standardized way. It acts as an intermediary, allowing AI models to communicate with databases, design tools, web browsers, and other applications seamlessly.\n",
      "\n",
      "2. **Key Features**:\n",
      "   - **Standardization**: MCP ensures consistency in the communication format between AI models and external tools. This means that whether an AI is interacting with a database or a web browser, the handshake and query format remain consistent.\n",
      "   - **Client-Server Architecture**: MCP operates on a client-server model where AI applications act as clients, and the tools or services they interact with act as servers. This architecture allows for lightweight MCP servers to expose data and functionalities to AI models.\n",
      "\n",
      "3. **Use Cases**:\n",
      "   - **Web Interaction**: Microsoft has launched a Playwright-MCP server that enables AI agents to browse the web and interact with websites. This is particularly useful for tasks that require real-time web data retrieval.\n",
      "   - **Database Queries**: MCP can standardize how AI models query databases, making it easier to integrate AI into existing data infrastructure.\n",
      "   - **Design Tools**: The protocol can facilitate interactions between AI models and design tools, enabling automated design processes.\n",
      "\n",
      "4. **Industry Support**:\n",
      "   - Major players like Microsoft and Amazon are supporting MCP. Amazon Bedrock Agents, for instance, leverage MCP to build AI applications that can interact with various tools and services.\n",
      "   - OpenAI‚Äôs support for MCP positions it as a leading standard in the agentic AI landscape.\n",
      "\n",
      "5. **Implementation Details**:\n",
      "   - Developers can expose their data through lightweight MCP servers, making it easier to integrate AI models into existing systems. The protocol ensures that the communication process is efficient and secure.\n",
      "\n",
      "6. **Critical Analysis**:\n",
      "   - While MCP offers many advantages, there are also critical analyses that discuss its limitations and potential improvements. For example, some argue that MCP mimics traditional client-server models, which may not be the most innovative approach for AI interactions.\n",
      "\n",
      "In summary, MCP is a crucial protocol in the development of agentic AI, providing a standardized way for AI models to interact with external tools and services. Its adoption by major tech companies underscores its importance and potential impact on the future of AI integration.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mLinkedIn Post Creator\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mCreate a LinkedIn post about \"mcp server and its influnce in Agentic AI\" using the influencer style and research.\n",
      "\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mLinkedIn Post Creator\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "üí° Ever wondered how AI agents can seamlessly interact with external tools and services? Enter MCP (Model Context Protocol) ‚Äì the game-changer in agentic AI! üöÄ\n",
      "\n",
      "Imagine an AI that can browse the web, query databases, and even design like a pro. That‚Äôs exactly what MCP makes possible. Developed by Anthropic, this protocol standardizes communication between AI models and various tools, ensuring consistency and efficiency.\n",
      "\n",
      "Here's why MCP is a big deal:\n",
      "\n",
      "üîë **Standardization**: Whether it's a database or a web browser, the communication format remains consistent.\n",
      "üåê **Web Interaction**: Microsoft‚Äôs Playwright-MCP server lets AI agents browse and interact with websites in real-time.\n",
      "üìä **Database Queries**: MCP makes integrating AI into existing data infrastructure a breeze.\n",
      "üé® **Design Tools**: Automate design processes by enabling AI interactions with design tools.\n",
      "\n",
      "Major players like Microsoft, Amazon, and OpenAI are backing MCP. Amazon Bedrock Agents use it to build AI applications that interact with various tools seamlessly. This support highlights its potential impact on the future of AI integration.\n",
      "\n",
      "But here‚Äôs where it gets even more exciting: MCP can be integrated into multi-agent systems, just like how I‚Äôve been exploring in my recent blog post, \"Think, Plan, Solve: A Smarter Way to Tackle Problems with Multi-Agent Planning.\" Imagine a team of autonomous agents that can think, plan, and solve complex problems using MCP to interact with external tools.\n",
      "\n",
      "üìñ Check out the blog here: [https://lnkd.in/g_ne9teQ](https://lnkd.in/g_ne9teQ)\n",
      "\n",
      "I‚Äôd love to hear your thoughts on how MCP could revolutionize agentic AI! Let‚Äôs build smarter agents and shape what‚Äôs next. üåü\n",
      "\n",
      "#AI #AgenticAI #MCP #MultiAgentSystems #AutonomousAgents #AIInnovation #FutureOfWork #AICommunity #opensource #Microsoft #Amazon #OpenAI\u001b[00m\n",
      "\n",
      "\n",
      "Here is the result: \n",
      "üí° Ever wondered how AI agents can seamlessly interact with external tools and services? Enter MCP (Model Context Protocol) ‚Äì the game-changer in agentic AI! üöÄ\n",
      "\n",
      "Imagine an AI that can browse the web, query databases, and even design like a pro. That‚Äôs exactly what MCP makes possible. Developed by Anthropic, this protocol standardizes communication between AI models and various tools, ensuring consistency and efficiency.\n",
      "\n",
      "Here's why MCP is a big deal:\n",
      "\n",
      "üîë **Standardization**: Whether it's a database or a web browser, the communication format remains consistent.\n",
      "üåê **Web Interaction**: Microsoft‚Äôs Playwright-MCP server lets AI agents browse and interact with websites in real-time.\n",
      "üìä **Database Queries**: MCP makes integrating AI into existing data infrastructure a breeze.\n",
      "üé® **Design Tools**: Automate design processes by enabling AI interactions with design tools.\n",
      "\n",
      "Major players like Microsoft, Amazon, and OpenAI are backing MCP. Amazon Bedrock Agents use it to build AI applications that interact with various tools seamlessly. This support highlights its potential impact on the future of AI integration.\n",
      "\n",
      "But here‚Äôs where it gets even more exciting: MCP can be integrated into multi-agent systems, just like how I‚Äôve been exploring in my recent blog post, \"Think, Plan, Solve: A Smarter Way to Tackle Problems with Multi-Agent Planning.\" Imagine a team of autonomous agents that can think, plan, and solve complex problems using MCP to interact with external tools.\n",
      "\n",
      "üìñ Check out the blog here: [https://lnkd.in/g_ne9teQ](https://lnkd.in/g_ne9teQ)\n",
      "\n",
      "I‚Äôd love to hear your thoughts on how MCP could revolutionize agentic AI! Let‚Äôs build smarter agents and shape what‚Äôs next. üåü\n",
      "\n",
      "#AI #AgenticAI #MCP #MultiAgentSystems #AutonomousAgents #AIInnovation #FutureOfWork #AICommunity #opensource #Microsoft #Amazon #OpenAI\n"
     ]
    }
   ],
   "source": [
    "from crewai import Agent, Task, Crew, LLM\n",
    "from tools import scrape_linkedin_posts_tool\n",
    "from crewai_tools import ScrapeWebsiteTool, SerperDevTool\n",
    "from tools.utils import load_yaml_file\n",
    "from dotenv import load_dotenv\n",
    "from textwrap import dedent\n",
    "import os\n",
    "\n",
    "load_dotenv(\"creds.env\")\n",
    "\n",
    "WORKER_MODEL = \"ollama/hf.co/unsloth/Mistral-Small-3.1-24B-Instruct-2503-GGUF:Q5_K_M\"\n",
    "OLLAMA_BASE_URL = \"http://localhost:11434\"\n",
    "\n",
    "ollama_llm = LLM(model=WORKER_MODEL, api_base=OLLAMA_BASE_URL, timeout=1200, temperature=0.1)\n",
    "\n",
    "# Tools\n",
    "tool_mapping = {\n",
    "    \"scrape_linkedin_posts_tool\": scrape_linkedin_posts_tool,\n",
    "    \"scrape_website_tool\": ScrapeWebsiteTool(),\n",
    "    \"search_tool\": SerperDevTool()\n",
    "}\n",
    "\n",
    "# Load YAML\n",
    "agent_defs = load_yaml_file(\"config/agents.yaml\")\n",
    "task_defs = load_yaml_file(\"config/tasks.yaml\")\n",
    "\n",
    "# Topic\n",
    "topic = input(\"Enter your topic (e.g., 'Llama 3 vs Llama 2'): \")\n",
    "\n",
    "# Create Agents\n",
    "agents = {}\n",
    "for name, config in agent_defs.items():\n",
    "    agents[name] = Agent(\n",
    "        role=config[\"role\"],\n",
    "        goal=config[\"goal\"],\n",
    "        backstory=dedent(config[\"backstory\"]),\n",
    "        tools=[tool_mapping[t] for t in config.get(\"assigned_tool_names\", [])],\n",
    "        verbose=True,\n",
    "        allow_delegation=False,\n",
    "        llm=ollama_llm\n",
    "    )\n",
    "\n",
    "# Create Tasks\n",
    "tasks = {}\n",
    "for name, config in task_defs.items():\n",
    "    task = Task(\n",
    "        description=dedent(config[\"description\"]).replace(\"{{topic}}\", topic),\n",
    "        expected_output=dedent(config[\"expected_output\"]).replace(\"{{topic}}\", topic),\n",
    "        agent=agents[config[\"agent\"]],\n",
    "    )\n",
    "    tasks[name] = task\n",
    "\n",
    "# Set Context\n",
    "for name, config in task_defs.items():\n",
    "    task = tasks[name]\n",
    "    context_names = config.get(\"context_task_names\", [])\n",
    "    if context_names:\n",
    "        task.context = [tasks[n] for n in context_names]\n",
    "\n",
    "# Run Crew\n",
    "crew = Crew(\n",
    "    agents=list(agents.values()),\n",
    "    tasks=list(tasks.values())\n",
    ")\n",
    "\n",
    "result = crew.kickoff()\n",
    "print(\"Here is the result: \")\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77ab3836-e73a-4676-a38b-37d9af54ff0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Climbing the AI Agents Staircase ‚Äì One Step Closer to the Future!Every day, I get more fired up about what‚Äôs possible with Agentic AI! From simple LLMs to fully autonomous systems capable of planning, decision-making, and even self-learning‚Äîthis is the frontier of innovation, and we‚Äôre right in the thick of it.This awesome visual below breaks it all down‚Äîfrom the basics to the advanced, showing how we move from connecting APIs and memory management‚Ä¶ all the way up to agents that can think, act, collaborate, and improve themselves.I just shared a new blog post where I dive into one of the most exciting parts of the journey:Designing autonomous planning and decision-making AI solutions.Check it out here: üß† Think, Plan, Solve: A Smarter Way to Tackle Problems with Multi-Agent Planning https://lnkd.in/g_ne9teQLet‚Äôs build smarter agents, stronger teams, and shape what‚Äôs next.If you‚Äôre working with agentic systems, I‚Äôd love to hear what excites you most!hashtag#AI hashtag#AgenticAI hashtag#AutonomousAgents hashtag#MultiAgentSystems hashtag#LLM hashtag#AIInnovation hashtag#FutureOfWork hashtag#AICommunity hashtag#opensource hashtag#IBM hashtag#MachineLearning hashtag#PromptEngineering', \"üí° How does ChatGPT process your questions behind the scenes?Have you ever wondered if there's an agentic AI solution that can: ‚ñ´Ô∏è Take a task from the user ‚ñ´Ô∏è Plan and assign a list of agents and tasks behind the scenes ‚ñ´Ô∏è Work step-by-step to solve complex problems intelligently?Sounds a lot like how ChatGPT thinks, plans, and solves ‚Äî right? üîÅIn my latest blog post, I introduce: üß† Think, Plan, Solve: A Smarter Way to Tackle Problems with Multi-Agent PlanningUsing open source hashtag#LLMs, hashtag#CrewAI and hashtag#Ollama, I built a system that: ‚úÖ Takes any user-defined goal ‚úÖ Breaks it down into a sequence of actionable tasks ‚úÖ Automatically architects a list of agents and tasks, saving them in YAML format ‚úÖ Dynamically assigns agents using the YAML configuration ‚úÖ Solves it recursively and adaptively ‚Äî like an autonomous team of thinkersüìñ Check out the blog: üëâ https://lnkd.in/g_ne9teQWould love to hear your thoughts and ideas! hashtag#AI hashtag#ThinkPlanSolve hashtag#MultiAgentSystems hashtag#LLM hashtag#AutonomousAgents hashtag#PromptEngineering hashtag#OpenSource hashtag#GenerativeAI hashtag#BeeAIP.S. While this version uses CrewAI, the concept is flexible ‚Äî you can use any multi-agent platform. I'm planning to try it next with BEEAI üëÄ Stay tuned!\"]\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "from tools import scrape_linkedin_posts_tool\n",
    "from tools import scrape_linkedin_posts_fn\n",
    "\n",
    "load_dotenv(\"creds.env\")\n",
    "\n",
    "\n",
    "print(scrape_linkedin_posts_fn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f59397ef-8fcd-448f-8d2b-bee25b003eed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting selenium\n",
      "  Downloading selenium-4.31.0-py3-none-any.whl.metadata (7.5 kB)\n",
      "Requirement already satisfied: urllib3<3,>=1.26 in /Users/skasmani/Downloads/personal/github/CrewAI-Worksatation/crewai-venv/lib/python3.12/site-packages (from urllib3[socks]<3,>=1.26->selenium) (2.3.0)\n",
      "Collecting trio~=0.17 (from selenium)\n",
      "  Downloading trio-0.29.0-py3-none-any.whl.metadata (8.5 kB)\n",
      "Collecting trio-websocket~=0.9 (from selenium)\n",
      "  Downloading trio_websocket-0.12.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /Users/skasmani/Downloads/personal/github/CrewAI-Worksatation/crewai-venv/lib/python3.12/site-packages (from selenium) (2025.1.31)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in /Users/skasmani/Downloads/personal/github/CrewAI-Worksatation/crewai-venv/lib/python3.12/site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: websocket-client~=1.8 in /Users/skasmani/Downloads/personal/github/CrewAI-Worksatation/crewai-venv/lib/python3.12/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: attrs>=23.2.0 in /Users/skasmani/Downloads/personal/github/CrewAI-Worksatation/crewai-venv/lib/python3.12/site-packages (from trio~=0.17->selenium) (25.3.0)\n",
      "Collecting sortedcontainers (from trio~=0.17->selenium)\n",
      "  Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: idna in /Users/skasmani/Downloads/personal/github/CrewAI-Worksatation/crewai-venv/lib/python3.12/site-packages (from trio~=0.17->selenium) (3.10)\n",
      "Collecting outcome (from trio~=0.17->selenium)\n",
      "  Using cached outcome-1.3.0.post0-py2.py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in /Users/skasmani/Downloads/personal/github/CrewAI-Worksatation/crewai-venv/lib/python3.12/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Collecting wsproto>=0.14 (from trio-websocket~=0.9->selenium)\n",
      "  Using cached wsproto-1.2.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting pysocks!=1.5.7,<2.0,>=1.5.6 (from urllib3[socks]<3,>=1.26->selenium)\n",
      "  Using cached PySocks-1.7.1-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /Users/skasmani/Downloads/personal/github/CrewAI-Worksatation/crewai-venv/lib/python3.12/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Downloading selenium-4.31.0-py3-none-any.whl (9.4 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading trio-0.29.0-py3-none-any.whl (492 kB)\n",
      "Downloading trio_websocket-0.12.2-py3-none-any.whl (21 kB)\n",
      "Using cached outcome-1.3.0.post0-py2.py3-none-any.whl (10 kB)\n",
      "Using cached PySocks-1.7.1-py3-none-any.whl (16 kB)\n",
      "Using cached wsproto-1.2.0-py3-none-any.whl (24 kB)\n",
      "Using cached sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Installing collected packages: sortedcontainers, wsproto, pysocks, outcome, trio, trio-websocket, selenium\n",
      "Successfully installed outcome-1.3.0.post0 pysocks-1.7.1 selenium-4.31.0 sortedcontainers-2.4.0 trio-0.29.0 trio-websocket-0.12.2 wsproto-1.2.0\n"
     ]
    }
   ],
   "source": [
    "# !pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8579ee64-3dfd-4d72-920b-15cf869c7779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\n",
      "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
      "\u001b[0m\n",
      "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
      "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://192.168.0.52:8501\u001b[0m\n",
      "\u001b[0m\n",
      "/Users/skasmani/Downloads/personal/github/CrewAI-Worksatation/crewai-venv/lib/python3.12/site-packages/pydantic/_internal/_config.py:295: PydanticDeprecatedSince20: Support for class-based `config` is deprecated, use ConfigDict instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  warnings.warn(DEPRECATION_MESSAGE, DeprecationWarning)\n",
      "/Users/skasmani/Downloads/personal/github/CrewAI-Worksatation/crewai-venv/lib/python3.12/site-packages/pydantic/_internal/_fields.py:192: UserWarning: Field name \"schema\" in \"DatabricksQueryToolSchema\" shadows an attribute in parent \"BaseModel\"\n",
      "  warnings.warn(\n",
      "/Users/skasmani/Downloads/personal/github/CrewAI-Worksatation/crewai-venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:502: UserWarning: <built-in function callable> is not a Python type (it may be an instance of an object), Pydantic will allow any object with no validation since we cannot even enforce that the input is an instance of the given type. To get rid of this error wrap the type with `pydantic.SkipValidation`.\n",
      "  warn(\n",
      "/Users/skasmani/Downloads/personal/github/CrewAI-Worksatation/crewai-venv/lib/python3.12/site-packages/crewai_tools/tools/scrapegraph_scrape_tool/scrapegraph_scrape_tool.py:34: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  @validator(\"website_url\")\n",
      "/Users/skasmani/Downloads/personal/github/CrewAI-Worksatation/crewai-venv/lib/python3.12/site-packages/crewai_tools/tools/selenium_scraping_tool/selenium_scraping_tool.py:26: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  @validator(\"website_url\")\n",
      "/Users/skasmani/Downloads/personal/github/CrewAI-Worksatation/crewai-venv/lib/python3.12/site-packages/crewai_tools/tools/vision_tool/vision_tool.py:15: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  @validator(\"image_path_url\")\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mLinkedIn Style Scraper\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mScrape a LinkedIn profile and extract 5 recent high-engagement posts to study tone and style.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mLinkedIn Style Scraper\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mScrapeLinkedinPosts\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"profile_url\\\": \\\"https://www.linkedin.com/in/alexander-lotorto/\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "['BOOM! The Llama-4 brood is out.- Scout: 16 experts, 17B each, 109B total parameters, 10M+ context window, can run on a single GPU.- Maverick: multimodal, 128 experts, 17B each, 400B total parameters, 1M context window.- preview of Behemoth: 16 experts, 288B each, 2T total parameters.Great performance numbers.', 'I shared a new tutorial + experiments on finetuning LLMs for classification efficiently. In this video, I explain how to convert a decoder-style LLM into a classifier. Many business problems are text classification problems, and if classification is all we need for a given task, using \"smaller\" and cheaper LLMs makes a lot of sense! (But, of course, also always run a simple logistic regression or naive Bayes baseline to determine if you even need a small LLM.)üß™ In addition, I also ran a series of 19 experiments to answer some \"what if\" questions around finetuning pretrained LLMs for classification. Here, I kept things simple and small (e.g., GPT-2 on a toy binary classification task):Here\\'s a snapshot summary of some of the interesting ones:1) As would be expected, training on the last token yields much better performance than the first2) Training the last transformer block is way better than just the last layer3) LoRA performs on par or better than full finetuning‚Äîwhile being faster and more memory-efficient4) Padding to full context length hurts performance 5) No padding or smart position selection leads to consistently higher accuracy6) Surprisingly, training from random weights isn\\'t much worse than using pretrained7) Averaging embeddings over all tokens can improve performance slightly with little costThe full video is available here: https://lnkd.in/gcfqR2mHPS: If you are wondering why GPT instead of BERT? Well, you can of course also use BERT. Based on experiments on the 50k Movie Review dataset It\\'s interesting though that this 3x smaller LLM performs on par (actually slightly better) than BERT. (ModernBERT then again is 2% better.)']\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mLinkedIn Style Scraper\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "Tone: Informative and Enthusiastic\n",
      "Structure:\n",
      "1. Sharing new tutorials or experiments.\n",
      "2. Providing detailed explanations of the process and findings.\n",
      "3. Using bullet points for clarity.\n",
      "4. Including links to further resources.\n",
      "Writing Patterns:\n",
      "1. Use of technical jargon specific to machine learning and LLMs.\n",
      "2. Detailed breakdowns of experimental results.\n",
      "3. Encouragement for viewers to try out the methods or experiments themselves.\n",
      "4. Comparison with other models or baselines to highlight performance differences.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mMarket Research Analyst\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mSearch and summarize high-quality articles, blogs, or posts about LLAMA 4 HIGHLIGHTS.\u001b[00m\n",
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mMarket Research Analyst\u001b[00m\n",
      "\u001b[95m## Thought:\u001b[00m \u001b[92mI need to start by searching the internet for relevant articles, blogs, or posts about LLAMA 4 HIGHLIGHTS. I will then read the content of these sources to gather detailed information.\u001b[00m\n",
      "\u001b[95m## Using tool:\u001b[00m \u001b[92mSearch the internet with Serper\u001b[00m\n",
      "\u001b[95m## Tool Input:\u001b[00m \u001b[92m\n",
      "\"{\\\"search_query\\\": \\\"LLAMA 4 HIGHLIGHTS\\\"}\"\u001b[00m\n",
      "\u001b[95m## Tool Output:\u001b[00m \u001b[92m\n",
      "{'searchParameters': {'q': 'LLAMA 4 HIGHLIGHTS', 'type': 'search', 'num': 10, 'engine': 'google'}, 'organic': [{'title': 'Ahmad Al-Dahle on X: \"Introducing our first set of Llama 4 models ...', 'link': 'https://x.com/Ahmad_Al_Dahle/status/1908595680828154198', 'snippet': \"Introducing our first set of Llama 4 models! We've been hard at work doing a complete re-design of the Llama series.\", 'position': 1}, {'title': 'Meta nears release of new AI model Llama 4 this month ... - Reuters', 'link': 'https://www.reuters.com/technology/artificial-intelligence/meta-nears-release-new-ai-model-llama-4-this-month-information-reports-2025-04-04/', 'snippet': \"The company was also concerned that Llama 4 was less capable than OpenAI's models in conducting humanlike voice conversations, the report added.\", 'position': 2}, {'title': \"Introducing our first set of Llama 4 models! We've been hard at work‚Ä¶\", 'link': 'https://www.linkedin.com/posts/ahmad-al-dahle_introducing-our-first-set-of-llama-4-models-activity-7314361939717984256-ljAY', 'snippet': 'Llama 4 Maverick is the best multimodal model in its class, beating GPT-4o and Gemini 2.0 Flash across a broad range of widely reported ...', 'position': 3}, {'title': 'Introducing our first set of Llama 4 models! - Threads', 'link': 'https://www.threads.net/@aaldahle/post/DIE3HmWyeya/introducing-our-first-set-of-llama-4-modelsweve-been-hard-at-work-doing-a-comple', 'snippet': 'The Llama series have been re-designed to use state of the art mixture-of-experts (MoE) architecture and natively trained with multimodality.', 'position': 4}, {'title': \"Meta Faces Challenges With Llama 4'S Upcoming Launch - Finimize\", 'link': 'https://finimize.com/content/meta-faces-challenges-with-llama-4s-upcoming-launch', 'snippet': \"Meta's Llama 4 journey highlights the industry-wide push to integrate advanced AI into business systems. With titans like Microsoft backing ...\", 'position': 5}, {'title': 'Llama 4 Day 0 Support on AMD Instinct GPUs - LinkedIn', 'link': 'https://www.linkedin.com/pulse/llama-4-day0-support-amd-instinct-gpus-amd-cgm5e', 'snippet': 'Key highlights include: Both MI300X and MI325X are capable of running the massive 400B-parameter Llama 4 Maverick in BF16 datatype on a ...', 'position': 6}, {'title': 'Llama 4 will probably suck : r/LocalLLaMA - Reddit', 'link': 'https://www.reddit.com/r/LocalLLaMA/comments/1jqa182/llama_4_will_probably_suck/', 'snippet': \"I hope I'm proven wrong of course, but the writing is kinda on the wall. Meta will probably fall behind and so will Montreal unfortunately.\", 'position': 7, 'sitelinks': [{'title': 'What are we expecting from Llama 4? : r/LocalLLaMA - Reddit', 'link': 'https://www.reddit.com/r/LocalLLaMA/comments/1hs6jjq/what_are_we_expecting_from_llama_4/'}, {'title': 'I think I found llama 4 - the \"cybele\" model on lmarena. It\\'s ... - Reddit', 'link': 'https://www.reddit.com/r/LocalLLaMA/comments/1jnbhdl/i_think_i_found_llama_4_the_cybele_model_on/'}]}, {'title': \"Meta's Llama 4: Revolutionizing AI with Omni Voice Features!\", 'link': 'https://opentools.ai/news/metas-llama-4-revolutionizing-ai-with-omni-voice-features', 'snippet': \"As Llama 4's release approaches, it also highlights the evolving landscape of AI ethics and governance. There's an acknowledged necessity ...\", 'position': 8}, {'title': 'Llama 4 to Revolutionize AI: What to Expect in 2025 - Magoven Studio', 'link': 'https://magoven.io/llama-4-to-revolutionize-ai-what-to-expect-in-2025/', 'snippet': 'Llama 4 is a huge leap forward for AI models developed by Meta. It plans to roll out more experiences for users across many applications by early 2025.', 'position': 9}], 'peopleAlsoAsk': [{'question': 'Which is better, llama or ChatGPT?', 'snippet': 'LLama is a preferred choice for researchers and organizations. ChatGPT is preferred by individuals for producing natural language texts.', 'title': 'LLama v/s ChatGPT: A Detailed Comparison Guide - Quytech', 'link': 'https://www.quytech.com/blog/llama-vs-chatgpt-comparison/'}, {'question': 'What is the llama 3 model?', 'snippet': 'LLaMA 3 features a tokenizer with a vocabulary of 128K tokens, improving language encoding efficiency and consequently enhancing model performance. Additionally, to boost the inference efficiency of Meta LLaMA 3 models, grouped query attention (GQA) was adopted across both the 8B and 70B sizes.', 'title': 'What is Meta LLaMA 3 ‚Äì The Most Capable Large Language Model', 'link': 'https://www.valuecoders.com/blog/ai-ml/what-is-meta-llama-3-large-language-model/'}, {'question': 'What does llama stand for?', 'snippet': 'What is LLaMA? LLaMA(Large Language Model Meta AI) is a collection of state-of-the-art foundation language models ranging from 7B to 65B parameters.', 'title': \"Introduction to Meta AI's LLaMA: Empowering AI Innovation\", 'link': 'https://www.datacamp.com/blog/introduction-to-meta-ai-llama'}], 'credits': 1}\u001b[00m\n"
     ]
    }
   ],
   "source": [
    "!streamlit run app.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130705ef-d33a-4dc2-9147-524df311de62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
