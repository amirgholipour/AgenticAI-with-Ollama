# ğŸ§  Local Multi-Agent Image Analysis with Open Source Tools

A fully offline, open-source AI system that extracts, interprets, and summarizes insights from any image â€” graphs, screenshots, dashboards, or photos â€” using **CrewAI**, **Streamlit**, and **Ollama-powered local LLMs**.
![App Screenshot](images/app.png)
---

## ğŸ–¼ï¸ What It Does

- ğŸ§© Breaks down visual data using **specialized agents** for text extraction, layout analysis, context reasoning, and narrative generation
- ğŸ” Detects insights from charts, screenshots, infographics, and more
- ğŸ¤– Simulates human-like understanding using a **multi-agent cognitive pipeline**
- ğŸ” Runs entirely **locally** using open-source models â€” **no API keys, no cloud**

---

## ğŸ§° Tech Stack

- [CrewAI](https://github.com/joaomdmoura/crewAI) â€“ Multi-agent framework for complex task delegation
- [Ollama](https://ollama.com) â€“ Local LLMs like `gemma`, `phi`, `granite`, `mxbai-embed-large`
- Streamlit â€“ Simple front-end to upload and analyze images
- Langchain + Unstructured â€“ OCR and text extraction from visual files

---

## ğŸ“¦ Project Structure

```
.
â”œâ”€â”€ app.py               # Streamlit frontend
â”œâ”€â”€ crew.py              # Core logic: agents + tasks
â”œâ”€â”€ tools.py             # Custom tools (OCR, layout detection)
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ agents.yaml      # Agent definitions
â”‚   â””â”€â”€ tasks.yaml       # Task definitions
â”œâ”€â”€ temp/                # Uploaded images
â”œâ”€â”€ images/              # App images
â”œâ”€â”€ requirements.txt     # Dependencies
â””â”€â”€ README.md
```

---

## âš™ï¸ How It Works

### ğŸ”¹ Agents (`config/agents.yaml`)

Each agent is a specialist with a defined responsibility:

- **Senior Vision-to-Text Specialist** â†’ Extracts readable text from the image
- **Senior Visual Structure Analyst** â†’ Interprets layout and element positions
- **Senior Visual Insight Architect** â†’ Determines what is important and why
- **Senior Insight Narrator** â†’ Produces a high-level human-like narrative

They run entirely on **local LLMs** via Ollama.

### ğŸ”¹ Tasks (`config/tasks.yaml`)

Tasks are delegated based on each agentâ€™s strengths:

- Extract text
- Analyze layout
- Determine image context and key elements
- Generate narrative summary

### ğŸ”¹ Tools (`tools.py`)

Instead of using `crewai.tools.VisionTool` (which doesnâ€™t work with Ollama/local models), we created **custom tools**:

- `TextExtractionTool` â€“ Uses `UnstructuredImageLoader` for OCR
- `ObjectLocationTool` â€“ Simulates spatial understanding of elements in image

These tools receive the image path and feed insights back to the agents.

---

## ğŸ§  Crew Execution (`crew.py`)

All agents and tasks are initialized and orchestrated through this function:

```python
def process_image(image_path: str):
    tasks = initialize_tasks(image_path)
    crew = Crew(
        agents=list(agents.values()),
        tasks=tasks,
        verbose=True,
        max_iterations=10,  # Prevent infinite loops
        embedder={"provider": "ollama", "config": {"model": "mxbai-embed-large"}}
    )
    result = crew.kickoff()
    return {
        "tasks_output": [task.output.__dict__ for task in crew.tasks],
        "token_usage": str(crew.usage_metrics),
    }
```

This ensures clean task execution, safe looping, and shared memory between agents via local embedding models.

---

## ğŸš€ Getting Started

### 1. Clone and Install

```bash
git clone https://github.com/YOUR_USERNAME/local-image-analyzer
cd local-image-analyzer
pip install -r requirements.txt
```

### 2. Start Ollama + Load Models

Make sure [Ollama](https://ollama.com) is installed and running.

Install the models:

```bash
ollama run gemma
ollama run phi
ollama run granite
ollama run mxbai-embed-large
```

### 3. Launch the App

```bash
streamlit run app.py
```

---

## ğŸ“ Sample Output

```
ğŸ“ Summary
ğŸ”¹ Task 1: Text Extraction â†’ Extracted citation metrics
ğŸ”¹ Task 2: Layout Analysis â†’ Identified grid layout of labels/values
ğŸ”¹ Task 3: Context Reasoning â†’ Prioritized metrics like h-index, i10-index
ğŸ”¹ Task 4: Human Summary â†’ Explained citation growth, patterns, and impact
```

---

## ğŸ’¡ Key Advantages

- **100% local**: No internet connection or OpenAI API key needed â€” perfect for secure, offline environments.
- **Open-source models**: Full transparency, customizable, and reproducible for enterprise use.
- **Modular YAML config**: Agents and tasks defined declaratively â€” scalable and clean.
- **Multi-domain ready**: Works with charts, dashboards, web UI, scenes, infographics, and more.

---

## ğŸ“ˆ Built For

- Privacy-sensitive AI research
- Educational analytics projects
- Visual summarization pipelines
- Document intelligence for offline environments

---

## ğŸ§± Future Work

- Use LayoutLM or vision transformers for real layout analysis
- Add follow-up Q&A on image contents
- Extend to medical, industrial, or legal domains

---

## ğŸ¤ Contributing

PRs welcome! Letâ€™s make local agentic intelligence stronger together.

---

## ğŸ“„ License

MIT â€“ do what you want, just give credit.

---

## ğŸ™Œ Acknowledgments

- [CrewAI](https://github.com/joaomdmoura/crewAI)
- [Ollama](https://ollama.com)
- Langchain, Unstructured, Streamlit

---

Built with â¤ï¸ for the open-source AI community.
